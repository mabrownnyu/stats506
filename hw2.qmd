---
title: "Homework 2"
format:
  html:
    embed-resources: true
editor: visual
author: "Megan Brown"
---

Github repo: <https://github.com/mabrownnyu/stats506>

```{r}
library(microbenchmark)
```

# Problem 1

## Problem 1(a)

### Version 1

```{r}

#' forLoopWalk (creates a random walk using a for loop)
#'
#' @param num An integer representing the number of steps we want to take
#'            in the walk
#' @param seed The random seed if desired, must be an integer
#'
#' @returns The final position from the walk
forLoopWalk <- function(num, seed=FALSE){
  
  # set random seed if there is one
  if(seed){
    set.seed(seed)
  }
  
  # start at position zero 
  positions <- 1:num
  
  # for each step, sample 1 or -1
  # then based on 1 or -1, choose 1, -1, -3, or 10
  for (step in 1:num){
    outcomes = c(1, -1, 10, -3)
    probabilities = c(0.475, 0.4, 0.025, 0.1)
    positions[step] = sample(outcomes, 1, prob=probabilities)
  }
  
  position <- 0
  for (i in positions){
    position <- position + i
  }
  # return the final position 
  return(position)
}
```

### Version 2

```{r}
#' vectorWalk (creates a random walk using R's built-in vectorization)
#'
#' @param num An integer representing the number of steps we want to take
#'            in the walk
#' @param seed The random seed if desired, must be an integer
#'
#' @returns The final position from the walk
vectorWalk <- function(num, seed=FALSE){
  if(seed){
    set.seed(seed)
  }
  # get a sample of every step with the according probabilities 
  positions <- sample(c(1, -1, 10, -3), size=num, prob=c(0.475, 0.4, 0.025, 0.1), replace=TRUE)
  
  # sum over steps to get the final positions
  position <- sum(positions)
  return(position)
}
```

### Version 3

```{r}
#' applyWalk (creates a random walk using R's apply function)
#'
#' @param num An integer representing the number of steps we want to take
#'            in the walk
#' @param seed The random seed if desired, must be an integer
#'
#' @returns The final position from the walk
applyWalk <- function(num, seed=FALSE){
  
  if(seed){
    set.seed(seed)
  }
  # set array
  positions <- 1:num
  # for each position, return a step based on the probabilities 
  positions <- sapply(positions, FUN=function(x){
    return(sample(x=c(1, -1, 10, -3), size=1, prob=c(0.475, 0.4, 0.025, 0.1)))
  })
  
  # add steps to find final position
  return(sum(unlist(positions)))
} 

```

### Verification that this worked

```{r}
# for ten samples
print(forLoopWalk(10))
print(vectorWalk(10))
print(applyWalk(10))

# for 1k samples
print(forLoopWalk(1000))
print(vectorWalk(1000))
print(applyWalk(1000))
```

## Problem 1(b)

```{r}
forLoopWalk(10, seed=330)
vectorWalk(10, seed=330)
applyWalk(10, seed=330)
```

```{r}
forLoopWalk(100, seed=330)
vectorWalk(100, seed=330)
applyWalk(100, seed=330)
```

## Problem 1(c)

```{r}
microbenchmark(vw1k=vectorWalk(1000),
               vw100k=vectorWalk(100000),
               flw1k=forLoopWalk(1000),
               flw100k=forLoopWalk(100000),
               aw1k=applyWalk(1000),
               aw100k=applyWalk(100000),
               unit="seconds"
               )
```

The vector walk is the fastest, and the for-loop and apply functions are slower. This is because the for loop walk is interpreted at every step of the for loop. The apply function is also not vectorized.

## Problem 1(d)

```{r}
n <- 10000
tests10 <- 1:n
tests10 <- sapply(tests10, FUN=vectorWalk, num=10)
100 * sum(tests10==0) / length(tests10)

tests100 <- 1:n
tests100 <- sapply(tests100, FUN=vectorWalk, num=100)
100 * sum(tests100==0) / length(tests100)

tests1k <- 1:n
tests1k <- sapply(tests1k, FUN=vectorWalk, num=1000)
100 * sum(tests1k==0) / length(tests1k)

```

When the number of steps is 10, the probability of the final step of the walk being 0 is 13.3%. When the number of steps is 100, the probability of the final step of the walk being 0 is 2.1%. When the number of steps is 1000, the probability of the final step of the walk being being 0 is 0.6%. I estimated these values by conducting 10k of the random walks and then calculating the number of times the final step was 0.

# Problem 2

```{r}
#' sampleDay (for n days, sample the number of cars based on the distribution per hour)
#'
#' @param n An integer representing the number of days we want to sample
#'
#' @returns The average number of cars per day
sampleDay <- function(n){
  # eight hours between midnight and seven
  midnight_to_seven <- rpois(n*8, lambda=1)
  # eight hours between nine and four
  nine_to_four <- rpois(n*8, lambda=8)
  # eight hours between six and eleven
  six_to_eleven <- rpois(n*6, lambda=12)
  # two hours for eight and five
  eight_and_five <- rnorm(n*2, mean=60, sd=sqrt(12))
  
  # sum total number of cars for every day
  total_cars <- sum(c(midnight_to_seven, nine_to_four, six_to_eleven, eight_and_five))
  
  # divide by number of days for average
  avg <- total_cars/n
  return(avg)
}

print(paste0("With 100 samples: ", sampleDay(100)))
print(paste0("With 1k samples: ", sampleDay(1000)))
print(paste0("With 10k samples: ", sampleDay(10000)))
print(paste0("With 100k samples: ", sampleDay(100000)))
```

The average number of cars that passes through the intersection every day is 264.

# Problem 3

```{r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
```

## Problem 3(a)

```{r}
# filter to columns without identifying information 
youtube <- youtube[,c("year", "funny", "show_product_quickly",
                      "patriotic", "celebrity", "danger", "animals",
                      "use_sex", "kind", "view_count", "like_count",
                      "dislike_count", "favorite_count", "comment_count",
                      "published_at", "category_id")]

dim(youtube)
```

The resulting dimensions are 247 rows and 16 columns.

## Problem 3(b)

```{r}
# likes
hist(youtube$like_count)
hist(log(youtube$like_count + 1), breaks=20)
```

```{r}
# dislikes
hist(youtube$dislike_count)
hist(log(youtube$dislike_count + 1), breaks=20)
```

```{r}
# views
hist(youtube$view_count)
hist(log(youtube$view_count + 1), breaks=20)
```

```{r}
# favorites
hist(youtube$favorite_count)
hist(log(youtube$favorite_count + 1), breaks=20)
```

`favorite_count` is not suitable because there is not variation in the values.

```{r}
# comments
hist(youtube$comment_count)
hist(log(youtube$comment_count + 1), breaks=20)
```

`like_count` and `view_count` are definitely suitable for outcomes since they are both (approximately) normally distributed after a log transformation. `dislike_count` and `comment_count` could also be used, but they are still a bit left-skewed after a log transformation. `favorite_count` is completely unsuitable for regression since there is no variation in the outcome variable.

```{r}
# do transformations discussed above
youtube$view_count <- log(youtube$view_count + 1)
youtube$like_count <- log(youtube$like_count + 1)
youtube$dislike_count <- log(youtube$dislike_count + 1)
youtube$comment_count <- log(youtube$comment_count + 1)

# transform true/false columns into integers
for (col in c("funny", "show_product_quickly", "patriotic",
              "celebrity", "danger", "animals", "use_sex")){
  youtube[,col] <- as.integer(youtube[,col])
}
```

## Problem 3(c)

### Views

```{r}
views <- lm(view_count ~ funny + show_product_quickly + patriotic
            + celebrity + danger + animals + use_sex + year, data=youtube
            )
summary(views)
```

### Likes

```{r}
likes <- lm(like_count ~ funny + show_product_quickly + patriotic
            + celebrity + danger + animals + use_sex + year, data=youtube
            )
summary(likes)
```

### Dislike Count

```{r}
dislikes <- lm(dislike_count ~ funny + show_product_quickly + patriotic
            + celebrity + danger + animals + use_sex + year, data=youtube
            )
summary(dislikes)
```

### Comment Count

```{r}
comments <- lm(comment_count ~ funny + show_product_quickly + patriotic
            + celebrity + danger + animals + use_sex + year, data=youtube
            )
summary(comments)
```

For each of the regressions, there were few statistically significant results. For views, there was no statistically significant attribute. For dislikes, like counts, and comment counts, year was statistically significant at the 0.1 level and positive, meaning ads created later had an increased number of dislikes, likes, and comments. Ads that were patriotic got more dislikes and comments. Ads that included danger received more likes.

## Problem 3(d)

```{r}

# drop where outcome is null
youtube <- youtube[!is.na(youtube$view_count),]

# outcomes
y <- youtube$view_count
y <- as.matrix(y)

# subset predictors
X <- youtube[,c("year", "funny", "show_product_quickly", "patriotic",
                "celebrity", "danger", "animals", "use_sex"
                )]

# transform true/false columns into integers
for (col in c("funny", "show_product_quickly", "patriotic",
              "celebrity", "danger", "animals", "use_sex")){
  X[,col] <- as.integer(X[,col])
}

X <- as.matrix(cbind(1, X))

# I used slides from STATS 500 Fall 2024 to verify that this formula 
# and code was correct. 
xtx <- t(X) %*% X
xtxi <- solve(xtx)
beta_hat <- xtxi %*% t(X) %*% youtube[,"view_count"]
beta_hat
```

```{r}
print(views$coefficients)
```

The coefficients are the same from the matrix multiplication and the `lm` function.

GPT disclosure: I used GPT to try and bug fix why my Quarto -\> HTML output was failing. I learned first that I had an extra whitespace in the yaml that was causing it to fail. Then, I learned that it was compiling slowly during the `microbenchmark` function and not actually failing.
